{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import re\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fnc = pd.read_csv('../input/trends-assessment-prediction/fnc.csv')\ndf_loading = pd.read_csv('../input/trends-assessment-prediction/loading.csv')\ndf_train_scores = pd.read_csv('../input/trends-assessment-prediction/train_scores.csv')\n\nfnc_features, loading_features = list(df_fnc.columns[1:]), list(df_loading.columns[1:])\ndf_train_scores['is_train'] = 1\ndf = df_fnc.merge(df_loading, on='Id')\ndf = df.merge(df_train_scores, how='left', on='Id')\n\ndf.loc[df['is_train'].isnull(), 'is_train'] = 0\ndf['is_train'] = df['is_train'].astype(np.uint8)\n\nprint(f'Static FNC Correlation Shape = {df_fnc.shape}')\nprint(f'Static FNC Correlation Memory Usage = {df_fnc.memory_usage().sum() / 1024 ** 2:.2f} MB')\nprint(f'sMRI SBM Loadings Shape = {df_loading.shape}')\nprint(f'sMRI SBM Loadings Memory Usage = {df_loading.memory_usage().sum() / 1024 ** 2:.2f} MB')\nprint(f'Train Scores Shape = {df_train_scores.shape}')\nprint(f'Train Scores Memory Usage = {df_train_scores.memory_usage().sum() / 1024 ** 2:.2f} MB')\nprint('-------------------------------------')\nprint(f'Train & Test Set Shape = {df.shape}')\nprint(f'Train & Test Set Memory Usage = {df.memory_usage().sum() / 1024 ** 2:.2f} MB')\n\ndel df_fnc, df_loading, df_train_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **1. Train Scores (Targets)**\n`train_scores.csv` is the file which consists of target features. Those features are `age`, `domain1_var1`, `domain1_var2`, `domain2_var1` and `domain2_var2`. There are 5 target features to predict and submissions are scored using feature-weighted, normalized absolute errors.\n\n**score** ${= \\Large \\sum\\limits_{f} w_{f} \\Big( \\frac{\\sum_{i} \\big| y_{f,i}  - \\hat{y}_{f,i}\\big| }{\\sum_{i} \\hat{y}_{f,i}} \\Big) }$\n\nThe weights are `[.3, .175, .175, .175, .175]` corresponding to features `[age, domain1_var1, domain1_var2, domain2_var1, domain2_var2]`. This means every targets normalized absolute error is independent from each other. They can be trained and predicted with a single model or 5 different models."},{"metadata":{},"cell_type":"markdown","source":"Even though some of target features are slightly tailed, all of them follow a normal distribution. Their descriptive statistical summary are very similar to each other.\n\nA small percentage of values are missing in target features except `age`. Target features in the same domain have same number of missing values and they are missing in same samples.  Those are skipped in the score calculation. However, every row should be predicted in the submission file."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_target(target_feature):    \n    \n    if target_feature == 'age':\n        print(f'Target feature {target_feature} Statistical Analysis\\n{\"-\" * 39}')\n    else:\n        print(f'Target feature {target_feature} Statistical Analysis\\n{\"-\" * 48}')\n        \n    print(f'Mean: {df[target_feature].mean():.4}  -  Median: {df[target_feature].median():.4}  -  Std: {df[target_feature].std():.4}')\n    print(f'Min: {df[target_feature].min():.4}  -  25%: {df[target_feature].quantile(0.25):.4}  -  50%: {df[target_feature].quantile(0.5):.4}  -  75%: {df[target_feature].quantile(0.75):.4}  -  Max: {df[target_feature].max():.4}')\n    print(f'Skew: {df[target_feature].skew():.4}  -  Kurtosis: {df[target_feature].kurtosis():.4}')\n    missing_values_count = df[(df['is_train'] == 1) & (df[target_feature]).isnull()].shape[0]\n    training_samples_count = df[df['is_train'] == 1].shape[0]\n    print(f'Missing Values: {missing_values_count}/{training_samples_count} ({missing_values_count * 100 / training_samples_count:.4}%)')\n\n    fig = plt.subplots(figsize=(6, 4), dpi=100)\n\n    sns.distplot(df[target_feature], label=target_feature)\n\n    plt.xlabel('')\n    plt.tick_params(axis='x', labelsize=12)\n    plt.tick_params(axis='y', labelsize=12)\n    plt.title(f'{target_feature} Distribution in Training Set')\n    plt.show()\n    \nfor target_feature in ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']:\n    plot_target(target_feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target features are not correlated with each other too much. The strongest correlations are between `age` and `domain1_var1` (**0.34**), and between  `age` and `domain2_var1` (**0.23**). There might be a relationship between  `age` and var1 features."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10), dpi=100)\n\nsns.heatmap(df[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].corr(),\n            annot=True,\n            square=True,\n            cmap='coolwarm',\n            annot_kws={'size': 14}, \n            fmt='.2f')   \n\nplt.tick_params(axis='x', labelsize=14, rotation=45)\nplt.tick_params(axis='y', labelsize=14, rotation=45)\n    \nplt.title('Target Features Correlations', size=18, pad=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **2. sMRI SBM Loadings**\nThe first set of features are source-based morphometry (SBM) loadings. These are subject-level weights from a group-level ICA decomposition of gray matter concentration maps from structural MRI (sMRI) scans. Those features are for both training and test samples.\n\nThere are **26** features in `loading.csv` file without `Id`. Those features are named from `IC_01` to `IC_30`, but `IC_19`, `IC_23`, `IC_25` and `IC_27` don't exist. They are parts of brain and their explanations are listed below:\n\n`\nIC_01 - Cerebellum\nIC_02 - ACC+mpfc\nIC_03 - Caudate\nIC_04 - Cerebellum\nIC_05 - Calcarine\nIC_06 - Calcarine\nIC_07 - Precuneus+PCC\nIC_08 - Frontal\nIC_09 - IPL+AG\nIC_10 - MTG\nIC_11 - Frontal\nIC_12 - SMA\nIC_13 - Temporal Pole\nIC_14 - Temporal Pole + Fusiform\nIC_15 - STG\nIC_16 - Middle Occipital?\nIC_17 - Cerebellum\nIC_18 - Cerebellum\nIC_20 - MCC\nIC_21 - Temporal Pole + Cerebellum\nIC_22 - Insula + Caudate\nIC_24 - IPL+Postcentral\nIC_26 - Inf+Mid Frontal\nIC_28 - Calcarine\nIC_29 - MTG\nIC_30 - Inf Frontal\n`\n\nAll of the loading features follow a normal distribution. Their distributions and descriptive statistical summary in training and test samples are very similar except `IC_20`. It is an exception because the distribution of `IC_20` in test samples is slightly shifted. This feature may require some preprocessing.\n\nNone of the loading features have a visible relationship with any of the targets. Data points of loading features are scattered around the means of `domain1_var1`, `domain1_var2`, `domain2_var1`, `domain2_var2`, however `age` has a tiny relationship with loading features. This relationship is not easy to detect but it looks like `age` is easier to predict than other target features."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_loading(loading_feature):    \n    \n    print(f'Loading feature {loading_feature} Statistical Analysis\\n{\"-\" * 42}')\n        \n    print(f'Mean: {df[loading_feature].mean():.4}  -  Median: {df[loading_feature].median():.4}  -  Std: {df[loading_feature].std():.4}')\n    print(f'Min: {df[loading_feature].min():.4}  -  25%: {df[loading_feature].quantile(0.25):.4}  -  50%: {df[loading_feature].quantile(0.5):.4}  -  75%: {df[loading_feature].quantile(0.75):.4}  -  Max: {df[loading_feature].max():.4}')\n    print(f'Skew: {df[loading_feature].skew():.4}  -  Kurtosis: {df[loading_feature].kurtosis():.4}')\n    missing_values_count = df[df[loading_feature].isnull()].shape[0]\n    training_samples_count = df.shape[0]\n    print(f'Missing Values: {missing_values_count}/{training_samples_count} ({missing_values_count * 100 / training_samples_count:.4}%)')\n\n    fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(25, 12), dpi=100, constrained_layout=True)\n    title_size = 18\n    label_size = 18\n\n    # Loading Feature Training and Test Set Distribution\n    sns.distplot(df[df['is_train'] == 1][loading_feature], label='Training', ax=axes[0][0])\n    sns.distplot(df[df['is_train'] == 0][loading_feature], label='Test', ax=axes[0][0])\n    axes[0][0].set_xlabel('')\n    axes[0][0].tick_params(axis='x', labelsize=label_size)\n    axes[0][0].tick_params(axis='y', labelsize=label_size)\n    axes[0][0].legend()\n    axes[0][0].set_title(f'{loading_feature} Distribution in Training and Test Set', size=title_size, pad=title_size)\n    \n    # Loading Feature vs age\n    sns.scatterplot(df[loading_feature], df['age'], ax=axes[0][1])\n    axes[0][1].set_title(f'{loading_feature} vs age', size=title_size, pad=title_size)\n    axes[0][1].set_xlabel('')\n    axes[0][1].set_ylabel('')\n    axes[0][1].tick_params(axis='x', labelsize=label_size)\n    axes[0][1].tick_params(axis='y', labelsize=label_size)\n    \n    # Loading Feature vs domain1_var1\n    sns.scatterplot(df[loading_feature], df['domain1_var1'], ax=axes[0][2])\n    axes[0][2].set_title(f'{loading_feature} vs domain1_var1', size=title_size, pad=title_size)\n    axes[0][2].set_xlabel('')\n    axes[0][2].set_ylabel('')\n    axes[0][2].tick_params(axis='x', labelsize=label_size)\n    axes[0][2].tick_params(axis='y', labelsize=label_size)\n    \n    # Loading Feature vs domain1_var2\n    sns.scatterplot(df[loading_feature], df['domain1_var2'], ax=axes[1][0])\n    axes[1][0].set_title(f'{loading_feature} vs domain1_var2', size=title_size, pad=title_size)\n    axes[1][0].set_xlabel('')\n    axes[1][0].set_ylabel('')\n    axes[1][0].tick_params(axis='x', labelsize=label_size)\n    axes[1][0].tick_params(axis='y', labelsize=label_size)\n    \n    # Loading Feature vs domain2_var1\n    sns.scatterplot(df[loading_feature], df['domain2_var1'], ax=axes[1][1])\n    axes[1][1].set_title(f'{loading_feature} vs domain2_var1', size=title_size, pad=title_size)\n    axes[1][1].set_xlabel('')\n    axes[1][1].set_ylabel('')\n    axes[1][1].tick_params(axis='x', labelsize=label_size)\n    axes[1][1].tick_params(axis='y', labelsize=label_size)\n    \n    # Loading Feature vs domain2_var2\n    sns.scatterplot(df[loading_feature], df['domain2_var2'], ax=axes[1][2])\n    axes[1][2].set_title(f'{loading_feature} vs domain2_var2', size=title_size, pad=title_size)\n    axes[1][2].set_xlabel('')\n    axes[1][2].set_ylabel('')\n    axes[1][2].tick_params(axis='x', labelsize=label_size)\n    axes[1][2].tick_params(axis='y', labelsize=label_size)\n    \n    plt.show()\n    \nfor loading_feature in sorted(loading_features):\n    plot_loading(loading_feature)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are strong correlations between `age` and some loading features that exceed **-0.4**, but none of the loading features are correlated with other targets.\n\nLoading features have decent correlations between themselves that exceed **0.5** and **-0.5**. Some of those high positive correlations belong to feature groups which are from the same part of the brain. However, all features from the same part of the brain are not necessarily correlated with each other, so there is no pattern here."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"loading_target_features = sorted(loading_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\nfig = plt.figure(figsize=(30, 30), dpi=100)\n\nsns.heatmap(df[loading_target_features].corr(),\n            annot=True,\n            square=True,\n            cmap='coolwarm',\n            annot_kws={'size': 15}, \n            fmt='.2f')   \n\nplt.tick_params(axis='x', labelsize=18, rotation=45)\nplt.tick_params(axis='y', labelsize=18, rotation=45)\n\nplt.title('Target and Loading Features Correlations', size=25, pad=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3. Static FNC Correlation Features**\nThe second set of features are static functional network connectivity (FNC) matrices. These are the subject-level cross-correlation values among 53 component timecourses estimated from GIG-ICA of resting state functional MRI (fMRI).\n\nThere are **1378** features in `fnc.csv` file without `Id`. Those features are named as `Network1(X)_vs_Network2(Y)` and there are **6** different networks. Network names and abbreviations are listed below:\n\n`\nSCN - Sub-cortical Network\nADN - Auditory Network\nSMN - Sensorimotor Network\nVSN - Visual Network\nCON - Cognitive-control Network    \nDMN - Default-mode Network\nCBN - Cerebellar Network\n`\n\nThose groups might be useful to analyze **1378** features part by part."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_fnc(fnc_feature):    \n    \n    print(f'FNC feature {fnc_feature} Statistical Analysis\\n{\"-\" * 51}')\n        \n    print(f'Mean: {df[fnc_feature].mean():.4}  -  Median: {df[fnc_feature].median():.4}  -  Std: {df[fnc_feature].std():.4}')\n    print(f'Min: {df[fnc_feature].min():.4}  -  25%: {df[fnc_feature].quantile(0.25):.4}  -  50%: {df[fnc_feature].quantile(0.5):.4}  -  75%: {df[fnc_feature].quantile(0.75):.4}  -  Max: {df[fnc_feature].max():.4}')\n    print(f'Skew: {df[fnc_feature].skew():.4}  -  Kurtosis: {df[fnc_feature].kurtosis():.4}')\n    missing_values_count = df[df[fnc_feature].isnull()].shape[0]\n    training_samples_count = df.shape[0]\n    print(f'Missing Values: {missing_values_count}/{training_samples_count} ({missing_values_count * 100 / training_samples_count:.4}%)')\n\n    fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(25, 12), dpi=100, constrained_layout=True)\n    title_size = 18\n    label_size = 18\n\n    # FNC Feature Training and Test Set Distribution\n    sns.distplot(df[df['is_train'] == 1][fnc_feature], label='Training', ax=axes[0][0])\n    sns.distplot(df[df['is_train'] == 0][fnc_feature], label='Test', ax=axes[0][0])\n    axes[0][0].set_xlabel('')\n    axes[0][0].tick_params(axis='x', labelsize=label_size)\n    axes[0][0].tick_params(axis='y', labelsize=label_size)\n    axes[0][0].legend()\n    axes[0][0].set_title(f'{fnc_feature} Distribution in Training and Test Set', size=title_size, pad=title_size)\n    \n    # FNC Feature vs age\n    sns.scatterplot(df[fnc_feature], df['age'], ax=axes[0][1])\n    axes[0][1].set_title(f'{fnc_feature} vs age', size=title_size, pad=title_size)\n    axes[0][1].set_xlabel('')\n    axes[0][1].set_ylabel('')\n    axes[0][1].tick_params(axis='x', labelsize=label_size)\n    axes[0][1].tick_params(axis='y', labelsize=label_size)\n    \n    # FNC Feature vs domain1_var1\n    sns.scatterplot(df[fnc_feature], df['domain1_var1'], ax=axes[0][2])\n    axes[0][2].set_title(f'{fnc_feature} vs domain1_var1', size=title_size, pad=title_size)\n    axes[0][2].set_xlabel('')\n    axes[0][2].set_ylabel('')\n    axes[0][2].tick_params(axis='x', labelsize=label_size)\n    axes[0][2].tick_params(axis='y', labelsize=label_size)\n    \n    # FNC Feature vs domain1_var2\n    sns.scatterplot(df[fnc_feature], df['domain1_var2'], ax=axes[1][0])\n    axes[1][0].set_title(f'{fnc_feature} vs domain1_var2', size=title_size, pad=title_size)\n    axes[1][0].set_xlabel('')\n    axes[1][0].set_ylabel('')\n    axes[1][0].tick_params(axis='x', labelsize=label_size)\n    axes[1][0].tick_params(axis='y', labelsize=label_size)\n    \n    # FNC Feature vs domain2_var1\n    sns.scatterplot(df[fnc_feature], df['domain2_var1'], ax=axes[1][1])\n    axes[1][1].set_title(f'{fnc_feature} vs domain2_var1', size=title_size, pad=title_size)\n    axes[1][1].set_xlabel('')\n    axes[1][1].set_ylabel('')\n    axes[1][1].tick_params(axis='x', labelsize=label_size)\n    axes[1][1].tick_params(axis='y', labelsize=label_size)\n    \n    # FNC Feature vs domain2_var2\n    sns.scatterplot(df[fnc_feature], df['domain2_var2'], ax=axes[1][2])\n    axes[1][2].set_title(f'{fnc_feature} vs domain2_var2', size=title_size, pad=title_size)\n    axes[1][2].set_xlabel('')\n    axes[1][2].set_ylabel('')\n    axes[1][2].tick_params(axis='x', labelsize=label_size)\n    axes[1][2].tick_params(axis='y', labelsize=label_size)\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3.1. Sub-cortical Network (SCN) Features**\n\nFirst FNC feature sub-group is SCN features. This is the smallest sub-group of fnc features and there are **10** features in it. This sub-group has cross-correlations with only itself.\n\nAll of the SCN features follow a normal distribution but they are slightly tailed. Their distributions and descriptive statistical summary in training and test samples are very similar, but some of the features have higher peaks in test samples.\n\nNone of the SCN features have a visible relationship with any of the targets. Data points of SCN features are scattered around the means of `domain1_var1`, `domain1_var2`, `domain2_var1`, `domain2_var2`, however `age` has a tiny relationship with SCN features.\n\nSome data points are very far away from mean clusters, they might be outliers."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"scn_pattern = r'SCN\\(\\d+\\)_vs_[A-Z]+\\(\\d+\\)'\nscn_features = [col for col in fnc_features if re.match(scn_pattern, col)]\n\nfor scn_feature in sorted(scn_features):\n    plot_fnc(scn_feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SCN features are strongly correlated with each other, but none of the SCN features are correlated with targets. Correlation between target and SCN features is even weaker than previous correlations."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"scn_target_features = sorted(scn_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\nfig = plt.figure(figsize=(25, 25), dpi=100)\n\nsns.heatmap(df[scn_target_features].corr(),\n            annot=True,\n            square=True,\n            cmap='coolwarm',\n            annot_kws={'size': 15}, \n            fmt='.2f')   \n\nplt.tick_params(axis='x', labelsize=18, rotation=75)\nplt.tick_params(axis='y', labelsize=18, rotation=0)\n\nplt.title('Target and SCN Features Correlations', size=25, pad=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3.2. Auditory Network (ADN) Features**\n\nSecond FNC feature sub-group is ADN features. This is also the second smallest sub-group of fnc features and there are **11** features in it. This sub-group has cross-correlations with SCN (10) and itself (1).\n\nAll of the ADN features follow a normal distribution but they are slightly tailed. Their distributions and descriptive statistical summary in training and test samples are very similar, but some of the features have higher peaks in test samples.\n\nNone of the ADN features have a visible relationship with any of the targets. Data points of ADN features are scattered around the means of `domain1_var1`, `domain1_var2`, `domain2_var1`, `domain2_var2` and `age`.\n\nIn features with tailed distributions, some data points are very far away from mean clusters, they might be outliers."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"adn_pattern = r'ADN\\(\\d+\\)_vs_[A-Z]+\\(\\d+\\)'\nadn_features = [col for col in fnc_features if re.match(adn_pattern, col)]\n\nfor adn_feature in sorted(adn_features):\n    plot_fnc(adn_feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADN features are strongly correlated with each other if only ADN is cross-correlated with SCN. There are **10** ADN(2) vs SCN(5) features and they have very strong correlation. There is only one ADN vs ADN (`ADN(56)_vs_ADN(21)`) feature and it doesn't have any significant correlation with anything. Correlations between target and ADN features is very weak which can be seen at the bottom and right end."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"adn_target_features = sorted(adn_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\nfig = plt.figure(figsize=(25, 25), dpi=100)\n\nsns.heatmap(df[adn_target_features].corr(),\n            annot=True,\n            square=True,\n            cmap='coolwarm',\n            annot_kws={'size': 15}, \n            fmt='.2f')   \n\nplt.tick_params(axis='x', labelsize=18, rotation=75)\nplt.tick_params(axis='y', labelsize=18, rotation=0)\n\nplt.title('Target and ADN Features Correlations', size=25, pad=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3.3. Sensorimotor Network (SMN) Features**\n\nThird FNC feature sub-group is SMN features. This is a large sub-group compared to previous ones and there are **99** features in it. This sub-group has cross-correlations with SCN (45), ADN (18) and itself (36).\n\nAll of the SMN features follow a normal distribution even though their shapes and tails vary a lot. Their distributions and descriptive statistical summary in training and test samples are very similar, but some of the features have small discrepancies.\n\nNone of the SMN features have a visible relationship with any of the targets. Data points of SMN features are scattered around the means of `domain1_var1`, `domain1_var2`, `domain2_var1`, `domain2_var2` and `age`.\n\nIn features with tailed distributions, some data points are very far away from mean clusters, they might be outliers."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"smn_pattern = r'SMN\\(\\d+\\)_vs_[A-Z]+\\(\\d+\\)'\nsmn_features = [col for col in fnc_features if re.match(smn_pattern, col)]\n\nfor smn_feature in sorted(smn_features):\n    plot_fnc(smn_feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is hard to identify correlations at feature level on this scale but it still gives lots of information. Since the feature names are sorted by alphabetical order, the correlations of feature groups are easy to detect.\n\nEvery cross-correlation of SMN have very strong correlations inside the second network groups. This explains the bright red blocks near the diagonal axis.\n\n* `SMN(X)_vs_ADN(Y)`: `X` is strongly correlated with every different `Y` value for `ADN` \n* `SMN(X)_vs_SCN(Y)`: `X` is strongly correlated with every different `Y` value for `SCN` \n* `SMN(X)_vs_SMN(Y)`: `X` is strongly correlated with every different `Y` value for `SMN`\n\nEvery cross-correlation of SMN have moderate correlations inside the first network groups. This explains the repeating skin and blue color blocks along the vertical and horizontal axis.\n\n* `SMN(X)_vs_ADN(Y)`: `Y` is strongly correlated with every different `X` value for `ADN` \n* `SMN(X)_vs_SCN(Y)`: `Y` is strongly correlated with every different `X` value for `SCN` \n* `SMN(X)_vs_SMN(Y)`: `Y` is strongly correlated with every different `X` value for `SMN`\n\nCorrelations between target and SMN features is very weak which can be seen at the bottom and right end."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"smn_target_features = sorted(smn_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\nfig = plt.figure(figsize=(40, 40), dpi=100)\n\nsns.heatmap(df[smn_target_features].corr(),\n            annot=False,\n            square=True,\n            cmap='coolwarm',\n            yticklabels=False,\n            xticklabels=False)   \n\nplt.tick_params(axis='x', labelsize=20, rotation=90)\nplt.tick_params(axis='y', labelsize=20, rotation=0)\n\nplt.title('Target and SMN Features Correlations', size=50, pad=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3.4. Visual Network (VSN) Features** \n\nFourth FNC feature sub-group is VSN features. This is a very large sub-group compared to previous ones and there are **180** features in it. This sub-group has cross-correlations with SCN (45), ADN (18), SMN (81) and itself (36).\n\nAll of the VSN features follow a normal distribution even though their shapes and tails vary a lot. Some of the features in this group have quite long tails in both sides. Their distributions and descriptive statistical summary in training and test samples are very similar, but some of the features have small discrepancies.\n\nSome of the VSN features have barely visible negative relationship with targets. Data points of VSN features are even more scattered around the means of `domain1_var1`, `domain1_var2`, `domain2_var1`, `domain2_var2` and `age`.\n\nIn features with heavy-tailed distributions, some data points are very far away from mean clusters, they might be outliers."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"vsn_pattern = r'VSN\\(\\d+\\)_vs_[A-Z]+\\(\\d+\\)'\nvsn_features = [col for col in fnc_features if re.match(vsn_pattern, col)]\n\nfor vsn_feature in sorted(vsn_features):\n    plot_fnc(vsn_feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is hard to identify correlations at feature level on this scale but it still gives lots of information. Since the feature names are sorted by alphabetical order, the correlations of feature groups are easy to detect. The same pattern from SMN features can be seen on VSN features as well.\n\nEvery cross-correlation of VSN have very strong correlations inside the second network groups. This explains the bright red blocks near the diagonal axis.\n\n* `VSN(X)_vs_ADN(Y)`: `X` is strongly correlated with every different `Y` value for `ADN` \n* `VSN(X)_vs_SCN(Y)`: `X` is strongly correlated with every different `Y` value for `SCN` \n* `VSN(X)_vs_SMN(Y)`: `X` is strongly correlated with every different `Y` value for `SMN`\n* `VSN(X)_vs_VSN(Y)`: `X` is strongly correlated with every different `Y` value for `VSN`\n\nEvery cross-correlation of VSN have moderate correlations inside the first network groups. This explains the repeating skin and blue color blocks along the vertical and horizontal axis.\n\n* `VSN(X)_vs_ADN(Y)`: `Y` is strongly correlated with every different `X` value for `ADN` \n* `VSN(X)_vs_SCN(Y)`: `Y` is strongly correlated with every different `X` value for `SCN` \n* `VSN(X)_vs_SMN(Y)`: `Y` is strongly correlated with every different `X` value for `SMN`\n* `VSN(X)_vs_VSN(Y)`: `Y` is strongly correlated with every different `X` value for `VSN`\n\nCorrelations between target and VSN features is very weak which can be seen at the bottom and right end."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"vsn_target_features = sorted(vsn_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\nfig = plt.figure(figsize=(40, 40), dpi=100)\n\nsns.heatmap(df[vsn_target_features].corr(),\n            annot=False,\n            square=True,\n            cmap='coolwarm',\n            yticklabels=False,\n            xticklabels=False)   \n\nplt.tick_params(axis='x', labelsize=20, rotation=90)\nplt.tick_params(axis='y', labelsize=20, rotation=0)\n\nplt.title('Target and VSN Features Correlations', size=50, pad=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3.5. Cognitive-Control Network (CON) Features** "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"con_pattern = r'CON\\(\\d+\\)_vs_[A-Z]+\\(\\d+\\)'\ncon_features = [col for col in fnc_features if re.match(con_pattern, col)]\n\nfor con_feature in sorted(con_features):\n    plot_fnc(con_feature)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"con_target_features = sorted(con_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\nfig = plt.figure(figsize=(50, 50), dpi=100)\n\nsns.heatmap(df[con_target_features].corr(),\n            annot=False,\n            square=True,\n            cmap='coolwarm',\n            yticklabels=False,\n            xticklabels=False)   \n\nplt.tick_params(axis='x', labelsize=20, rotation=90)\nplt.tick_params(axis='y', labelsize=20, rotation=0)\n\nplt.title('Target and CON Features Correlations', size=50, pad=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To Be Continued","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}